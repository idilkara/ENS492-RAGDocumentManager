This is to run a llm server on port 30000 using docker

there is a shell script for this you can modify or just run your model I dont care. 

ollama-config.sh 