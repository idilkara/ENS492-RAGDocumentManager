flowchart TD

subgraph RAG_pipeline

    A[User submits a question] 
    A --> O         
    A --> B   
    M[combine and create request
    to LLM ] --> Z
    E --> M
    I --> M
    L --> M
    

    subgraph Response_Generation
   
        Z[LLM: Generates Context
            -aware Response]
        Z --> N[Output Answer, 
                Reference to document 
                chunks,
                source metadata
                ]
        
    
    end 

    subgraph Session_Context
       
        O[Previous Session 
            Context:
            Chat History
            stored in MongoDB
            ] 
        
         O -->  E[Prepare history buffer
        based on token count 
        for length]

        

    end



    subgraph Query_Analysis

        B[Structural analysis: 
            Language Detection 
            & Token Counting]

        B --> C[Semantic-aware Analysis:
                Condense & Refocus Query
            with LangChain's 
                ConversationalRetrieval-
                Chain
                ]


    end




    subgraph Chunk_Retrieval

        C -->  H[Apply MMR Search to
            select the top relevant
            chunks stored in ChromaDB
            ]

        H --> I[Re-rank with FlashRank:
                Cross Encoder for Semantic 
                Similarity]

    end


    subgraph Prompt_Template

        L[Language Specific Rules 
            and Behavioral Instructions]
       

    end


end

    
    %% Styling

    classDef outer fill:#ffffff,stroke:#01579b,stroke-width:1px

    classDef blue fill:#e1f5fe,stroke:#01579b,stroke-width:2px

    class RAG_pipeline outer
    class Response_Generation blue
    class Chunk_Retrieval blue
    class Session_Context,Query_Analysis,Prompt_Template blue
